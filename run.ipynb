{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CS-433 Machine learning project 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import helpers\n",
    "from functions import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = np.genfromtxt(\"data/dataset/x_train.csv\", delimiter=',', skip_header=1)\n",
    "y_train = np.genfromtxt(\"data/dataset/y_train.csv\", delimiter=',', skip_header=1)\n",
    "x_test =  np.genfromtxt(\"data/dataset/x_test.csv\", delimiter=',', skip_header=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2015. 2015. 2015. ... 2015. 2015. 2015.]\n",
      "float64\n",
      "False\n",
      "139415\n"
     ]
    }
   ],
   "source": [
    "print(x_train[:,5])\n",
    "print(x_train[0,5].dtype)\n",
    "print(np.isnan(x_train[0,5]))\n",
    "print(np.sum(np.isnan(x_train[:,10])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Nan handling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[     0      0      0      0      0      0      0      0      0 139415\n",
      " 139415 328103 139416 139415 328103 139433 139524 139525 188720 188720\n",
      " 188721 188720 327334 188719 189287 192544      2      1      0 159860\n",
      "      0      0      1      1      1 196334      0  43801  43801      0\n",
      "      0 284153      1      0      0      1      0      0      5 285915\n",
      "      0      0      0      0 139415 318245 139415      1      0      3\n",
      "   2471   3207   3946   4407 279663   6933   7743   8293   8728   9149\n",
      "   9432   9862  10541 191379 282510 237369  11007  11765 170906 171212\n",
      " 171522  20738  21567  22468  23149  23759  24502  26205 107829 109141\n",
      " 109407 109690 181261 181400  28647 226907 227043 227197 229088  29911\n",
      "  30600 186763 186001  31022  32080 243418 243561 266689 266689 306425\n",
      " 306426 306428 306429 306429 306629 306429 306430 306430 247299 310302\n",
      " 310320 310346 310367 310392 310403 310450 265347 325762 325769 325769\n",
      " 327339 326264 325775 325777 325777 325780 241493 318477 318489 325051\n",
      " 318505 318515 297518 309300 297543 327354 327645 327907 327907 327648\n",
      " 327648 327649 327793 327650 327650 327362 327618 314089 318284 323942\n",
      " 323941 323942 313550 313560 313564 313572 298044 320046 327036 307336\n",
      " 311136 314308 311142 312277 311151 322950 311321 323914 324421 287897\n",
      " 313435 287921 298973 298976 323261 323267 323272 323272 325495 325498\n",
      " 327539 327956 276513 273642 302161 302172 309175 299744 203924 203990\n",
      " 283588 283743 289046 323324 313056 313066 312994 313007 313014 313018\n",
      " 313027 313032 313044 313055 313067 313074      0     14 142438      0\n",
      "     22      0      0  90436 279532 279532 283603      0 123084      0\n",
      "      0      0      0      0  43801      0      0      0   1883      0\n",
      "      0      0      0      0      0   5438      0      0      0      0\n",
      "  12721  11368  23006  27073  27073      0      0      0      0      0\n",
      "      0      0      0      0      0      0  28366  26927  29382  27893\n",
      "  28958  30593      0      0      0      0  32115  37605      0      0\n",
      "      0      0      0      0      0 108727 112425      0      0 111072\n",
      " 114698 113793 184643 111257 182913 115152 116821  32496      0 117355\n",
      " 119004 112859 113785 117012 111793      0      0      0      0      0\n",
      "      0      0      0   1883   1883   1883      0      0 211378 211378\n",
      "  32080]\n",
      "146965.04361370715\n",
      "(321,)\n",
      "321\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#calculate number number of nan per column\n",
    "logical_matrix = np.isnan(x_train)\n",
    "nan_per_columns = np.sum(logical_matrix, axis=0)\n",
    "print(nan_per_columns)\n",
    "average_nan = np.mean(nan_per_columns)\n",
    "print(average_nan)\n",
    "print(np.shape(nan_per_columns))\n",
    "print(np.shape(x_train)[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# delet the columns with more nan than the average\n",
    "x_train_reduced_features = x_train[:, nan_per_columns <= average_nan]\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(328135, 321)\n"
     ]
    }
   ],
   "source": [
    "print(np.shape(x_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "#replace nan values with the mean:\n",
    "x_train_w_mean = x_train\n",
    "for i in range( np.shape(x_train)[1]):\n",
    "    nan_entries = np.isnan(x_train[:,i])\n",
    "    mean = np.mean(x_train[~nan_entries,i])\n",
    "\n",
    "    nan_entries = np.isnan(x_train[:,i])\n",
    "\n",
    "    x_train_w_mean[nan_entries, i] = mean\n",
    "    \n",
    "logical_matrix = np.isnan(x_train_w_mean)\n",
    "nan_per_columns2 = np.sum(logical_matrix, axis=0)\n",
    "print(nan_per_columns2)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1.43629640e+00  1.33036073e+00  1.31787257e+00 ... -4.98941290e-12\n",
      "   2.63592491e-12  2.44635873e-02]\n",
      " [ 1.88772178e-01  1.61711904e+00  1.60160179e+00 ... -4.98941290e-12\n",
      "   2.63592491e-12 -2.90142707e-13]\n",
      " [-6.22118565e-01  1.04360241e+00  1.04274121e+00 ... -8.59212775e-01\n",
      "  -2.46031587e-01  2.44635873e-02]\n",
      " ...\n",
      " [ 5.63029444e-01  1.04360241e+00  1.04274121e+00 ... -1.93109791e-01\n",
      "  -2.46031587e-01  2.44635873e-02]\n",
      " [ 1.88772178e-01  1.61711904e+00  1.64459107e+00 ... -4.98941290e-12\n",
      "   2.63592491e-12  2.44635873e-02]\n",
      " [ 1.26395967e-01  7.56844099e-01  7.33218431e-01 ... -4.98941290e-12\n",
      "   2.63592491e-12  2.44635873e-02]]\n"
     ]
    }
   ],
   "source": [
    "x_train_std, _, _, = standardize(x_train_w_mean)\n",
    "print(x_train_std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(328135, 321)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "print(np.shape(x_train_std))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 91.17 % zeros.\n",
      "\n",
      "There are 8.83 % ones.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "### Count the amount of incidents\n",
    "\n",
    "zeros = np.sum((y_train == 0))\n",
    "\n",
    "ones = np.sum(( y_train == 1))\n",
    "print(f\"There are {100*zeros/len(y_train):.2f} % zeros.\\n\")\n",
    "print(f\"There are {100*ones/len(y_train):.2f} % ones.\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'sigmoid' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/mnt/c/Users/thami/OneDrive/Dokumente/EPFL/Master/3_Semester/ML/ML_Project1/run.ipynb Cell 13\u001b[0m line \u001b[0;36m3\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu/mnt/c/Users/thami/OneDrive/Dokumente/EPFL/Master/3_Semester/ML/ML_Project1/run.ipynb#X15sdnNjb2RlLXJlbW90ZQ%3D%3D?line=21'>22</a>\u001b[0m \u001b[39m\"\"\" #1) mean_squared_error_gd\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu/mnt/c/Users/thami/OneDrive/Dokumente/EPFL/Master/3_Semester/ML/ML_Project1/run.ipynb#X15sdnNjb2RlLXJlbW90ZQ%3D%3D?line=22'>23</a>\u001b[0m \u001b[39mw, loss = mean_squared_error_gd(y, tx, w, max_iters, gamma)\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu/mnt/c/Users/thami/OneDrive/Dokumente/EPFL/Master/3_Semester/ML/ML_Project1/run.ipynb#X15sdnNjb2RlLXJlbW90ZQ%3D%3D?line=23'>24</a>\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu/mnt/c/Users/thami/OneDrive/Dokumente/EPFL/Master/3_Semester/ML/ML_Project1/run.ipynb#X15sdnNjb2RlLXJlbW90ZQ%3D%3D?line=30'>31</a>\u001b[0m \u001b[39m#4) ridge_regression\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu/mnt/c/Users/thami/OneDrive/Dokumente/EPFL/Master/3_Semester/ML/ML_Project1/run.ipynb#X15sdnNjb2RlLXJlbW90ZQ%3D%3D?line=31'>32</a>\u001b[0m \u001b[39mw, loss = ridge_regression(y, tx, lambda_) \"\"\"\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu/mnt/c/Users/thami/OneDrive/Dokumente/EPFL/Master/3_Semester/ML/ML_Project1/run.ipynb#X15sdnNjb2RlLXJlbW90ZQ%3D%3D?line=33'>34</a>\u001b[0m \u001b[39m#5) logistic_regression\u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell://wsl%2Bubuntu/mnt/c/Users/thami/OneDrive/Dokumente/EPFL/Master/3_Semester/ML/ML_Project1/run.ipynb#X15sdnNjb2RlLXJlbW90ZQ%3D%3D?line=34'>35</a>\u001b[0m w, loss \u001b[39m=\u001b[39m logistic_regression(y, tx, w, max_iters, gamma)\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu/mnt/c/Users/thami/OneDrive/Dokumente/EPFL/Master/3_Semester/ML/ML_Project1/run.ipynb#X15sdnNjb2RlLXJlbW90ZQ%3D%3D?line=36'>37</a>\u001b[0m \u001b[39m\"\"\" #6) reg_logistic_regression\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu/mnt/c/Users/thami/OneDrive/Dokumente/EPFL/Master/3_Semester/ML/ML_Project1/run.ipynb#X15sdnNjb2RlLXJlbW90ZQ%3D%3D?line=37'>38</a>\u001b[0m \u001b[39mw, loss = reg_logistic_regression(y, tx, w, max_iters, gamma, lambda_) \"\"\"\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu/mnt/c/Users/thami/OneDrive/Dokumente/EPFL/Master/3_Semester/ML/ML_Project1/run.ipynb#X15sdnNjb2RlLXJlbW90ZQ%3D%3D?line=39'>40</a>\u001b[0m losses\u001b[39m.\u001b[39mappend(loss)\n",
      "File \u001b[0;32m/mnt/c/Users/thami/OneDrive/Dokumente/EPFL/Master/3_Semester/ML/ML_Project1/functions.py:124\u001b[0m, in \u001b[0;36mlogistic_regression\u001b[0;34m(y, tx, initial_w, max_iters, gamma)\u001b[0m\n\u001b[1;32m    122\u001b[0m w \u001b[39m=\u001b[39m initial_w\n\u001b[1;32m    123\u001b[0m \u001b[39mfor\u001b[39;00m n_iter \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(max_iters):\n\u001b[0;32m--> 124\u001b[0m     gradient \u001b[39m=\u001b[39m compute_gradient_logistic(y, tx, w)\n\u001b[1;32m    125\u001b[0m     loss \u001b[39m=\u001b[39m compute_loss_logistic(y, tx, w)\n\u001b[1;32m    126\u001b[0m     w \u001b[39m=\u001b[39m w \u001b[39m-\u001b[39m gamma \u001b[39m*\u001b[39m gradient\n",
      "File \u001b[0;32m/mnt/c/Users/thami/OneDrive/Dokumente/EPFL/Master/3_Semester/ML/ML_Project1/functions.py:48\u001b[0m, in \u001b[0;36mcompute_gradient_logistic\u001b[0;34m(y, tx, w)\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[39m\"\"\"compute the gradient of loss.\"\"\"\u001b[39;00m\n\u001b[1;32m     47\u001b[0m pred \u001b[39m=\u001b[39m tx\u001b[39m.\u001b[39mdot(w)\n\u001b[0;32m---> 48\u001b[0m gradient \u001b[39m=\u001b[39m tx\u001b[39m.\u001b[39mT\u001b[39m.\u001b[39mdot(sigmoid(pred) \u001b[39m-\u001b[39m y)\n\u001b[1;32m     49\u001b[0m \u001b[39mreturn\u001b[39;00m gradient\n",
      "\u001b[0;31mNameError\u001b[0m: name 'sigmoid' is not defined"
     ]
    }
   ],
   "source": [
    "tx = x_train_std[:1000, [10, 12, 14]] # change input data here\n",
    "y = y_train[:1000] # change target value here\n",
    "y = y.reshape(-1, 1)\n",
    "\n",
    "\n",
    "\n",
    "w_s=[]\n",
    "losses=[]\n",
    "w = np.full((tx.shape[1],1), 1e-16) \n",
    "\n",
    "max_iters=100\n",
    "accs=[]\n",
    "precs=[]\n",
    "recs=[]\n",
    "F1s=[]\n",
    "batch_size = 1 \n",
    "lambda_ = 1e-3\n",
    "gamma = 0.1\n",
    "#1) mean_squared_error_gd \n",
    "for i in range(max_iters):\n",
    "\n",
    "    \"\"\" #1) mean_squared_error_gd\n",
    "    w, loss = mean_squared_error_gd(y, tx, w, max_iters, gamma)\n",
    "\n",
    "    #2) mean_squared_error_sgd\n",
    "    w, loss = mean_squared_error_sgd(y, tx, w, max_iters, gamma)\n",
    "\n",
    "    #3) least_squares\n",
    "    w, loss = least_squares(y, tx)  # change input data here, matrix is not invertible\n",
    "\n",
    "    #4) ridge_regression\n",
    "    w, loss = ridge_regression(y, tx, lambda_) \"\"\"\n",
    "\n",
    "    #5) logistic_regression\n",
    "    w, loss = logistic_regression(y, tx, w, max_iters, gamma)\n",
    "\n",
    "    \"\"\" #6) reg_logistic_regression\n",
    "    w, loss = reg_logistic_regression(y, tx, w, max_iters, gamma, lambda_) \"\"\"\n",
    " \n",
    "    losses.append(loss)\n",
    "\n",
    " \n",
    "    y_pred=tx.dot(w)\n",
    "    y_pred = compute_sigmoid(y_pred)\n",
    "    y_pred[y_pred>0.5] = 1\n",
    "    y_pred[y_pred<=0.5] = 0\n",
    "    \n",
    "    TP = 0\n",
    "    FP = 0\n",
    "    TN = 0\n",
    "    FN = 0\n",
    "    for pred in range(len(y_pred)):\n",
    "        if (y_pred[pred] == 1 and y[pred] == 1):\n",
    "            TP+=1\n",
    "        elif (y_pred[pred] == 1 and y[pred] == 0):\n",
    "            FP+=1\n",
    "        elif (y_pred[pred] == 0 and y[pred] == 1):\n",
    "            FN+=1\n",
    "        else :\n",
    "            TN+=1\n",
    "    acc = (TP+TN)/len(y_pred)\n",
    "    prec = TP/(TP+FP)\n",
    "    rec = TP/(TP+FN)\n",
    "    if prec + rec == 0:\n",
    "        F1score = 0  # Avoid division by zero\n",
    "    else:\n",
    "        F1score = 2 * prec * rec / (prec + rec)\n",
    "\n",
    "    if acc > 0.75 :\n",
    "        w_s.append(w)\n",
    "\n",
    "    accs.append(acc)\n",
    "    precs.append(prec)\n",
    "    recs.append(recs)\n",
    "    F1s.append(F1score)\n",
    "    conf_matrix = np.array([[TP, FP], [FN, TN]])\n",
    "        \n",
    "w_s = np.asarray(w_s)\n",
    "print(\"lambda = \",lambda_,\"| Accuracy moyenne :\",np.mean(accs),\"| Acc>0.75 :\",w_s.shape[0])\n",
    "print(accs)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure()\n",
    "plt.plot(np.linspace(0, max_iters, max_iters), accs)\n",
    "plt.xlabel(\"Iterations\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "CIVIL-459",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
