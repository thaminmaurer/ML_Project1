{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CS-433 Machine learning project 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import helpers\n",
    "from functions import *\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x_train = np.genfromtxt(\"data/dataset/x_train.csv\", delimiter=',', skip_header=1)\n",
    "# y_train = np.genfromtxt(\"data/dataset/y_train.csv\", delimiter=',', skip_header=1)\n",
    "# x_test =  np.genfromtxt(\"data/dataset/x_test.csv\", delimiter=',', skip_header=1)\n",
    "x_train, x_test, y_train, train_ids, test_ids = helpers.load_csv_data(\"data/dataset\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2015. 2015. 2015. ... 2015. 2015. 2015.]\n",
      "float64\n",
      "False\n",
      "139415\n",
      "[-1 -1 -1 ... -1 -1 -1]\n"
     ]
    }
   ],
   "source": [
    "print(x_train[:,5])\n",
    "print(x_train[0,5].dtype)\n",
    "print(np.isnan(x_train[0,5]))\n",
    "print(np.sum(np.isnan(x_train[:,10])))\n",
    "print(y_train)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Nan handling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[     0      0      0      0      0      0      0      0      0 139415\n",
      " 139415 328103 139416 139415 328103 139433 139524 139525 188720 188720\n",
      " 188721 188720 327334 188719 189287 192544      2      1      0 159860\n",
      "      0      0      1      1      1 196334      0  43801  43801      0\n",
      "      0 284153      1      0      0      1      0      0      5 285915\n",
      "      0      0      0      0 139415 318245 139415      1      0      3\n",
      "   2471   3207   3946   4407 279663   6933   7743   8293   8728   9149\n",
      "   9432   9862  10541 191379 282510 237369  11007  11765 170906 171212\n",
      " 171522  20738  21567  22468  23149  23759  24502  26205 107829 109141\n",
      " 109407 109690 181261 181400  28647 226907 227043 227197 229088  29911\n",
      "  30600 186763 186001  31022  32080 243418 243561 266689 266689 306425\n",
      " 306426 306428 306429 306429 306629 306429 306430 306430 247299 310302\n",
      " 310320 310346 310367 310392 310403 310450 265347 325762 325769 325769\n",
      " 327339 326264 325775 325777 325777 325780 241493 318477 318489 325051\n",
      " 318505 318515 297518 309300 297543 327354 327645 327907 327907 327648\n",
      " 327648 327649 327793 327650 327650 327362 327618 314089 318284 323942\n",
      " 323941 323942 313550 313560 313564 313572 298044 320046 327036 307336\n",
      " 311136 314308 311142 312277 311151 322950 311321 323914 324421 287897\n",
      " 313435 287921 298973 298976 323261 323267 323272 323272 325495 325498\n",
      " 327539 327956 276513 273642 302161 302172 309175 299744 203924 203990\n",
      " 283588 283743 289046 323324 313056 313066 312994 313007 313014 313018\n",
      " 313027 313032 313044 313055 313067 313074      0     14 142438      0\n",
      "     22      0      0  90436 279532 279532 283603      0 123084      0\n",
      "      0      0      0      0  43801      0      0      0   1883      0\n",
      "      0      0      0      0      0   5438      0      0      0      0\n",
      "  12721  11368  23006  27073  27073      0      0      0      0      0\n",
      "      0      0      0      0      0      0  28366  26927  29382  27893\n",
      "  28958  30593      0      0      0      0  32115  37605      0      0\n",
      "      0      0      0      0      0 108727 112425      0      0 111072\n",
      " 114698 113793 184643 111257 182913 115152 116821  32496      0 117355\n",
      " 119004 112859 113785 117012 111793      0      0      0      0      0\n",
      "      0      0      0   1883   1883   1883      0      0 211378 211378\n",
      "  32080]\n",
      "146965.04361370715\n",
      "(321,)\n",
      "321\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#calculate number number of nan per column\n",
    "logical_matrix = np.isnan(x_train)\n",
    "nan_per_columns = np.sum(logical_matrix, axis=0)\n",
    "print(nan_per_columns)\n",
    "average_nan = np.mean(nan_per_columns)\n",
    "print(average_nan)\n",
    "print(np.shape(nan_per_columns))\n",
    "print(np.shape(x_train)[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# delet the columns with more nan than the average\n",
    "x_train_reduced_features = x_train[:, nan_per_columns <= average_nan]\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(328135, 321)\n"
     ]
    }
   ],
   "source": [
    "print(np.shape(x_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "#replace nan values with the mean:\n",
    "x_train_w_mean = x_train\n",
    "for i in range( np.shape(x_train)[1]):\n",
    "    nan_entries = np.isnan(x_train[:,i])\n",
    "    mean = np.mean(x_train[~nan_entries,i])\n",
    "\n",
    "    nan_entries = np.isnan(x_train[:,i])\n",
    "\n",
    "    x_train_w_mean[nan_entries, i] = mean\n",
    "    \n",
    "logical_matrix = np.isnan(x_train_w_mean)\n",
    "nan_per_columns2 = np.sum(logical_matrix, axis=0)\n",
    "print(nan_per_columns2)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1.43629640e+00  1.33036073e+00  1.31787257e+00 ... -4.98941290e-12\n",
      "   2.63592491e-12  2.44635873e-02]\n",
      " [ 1.88772178e-01  1.61711904e+00  1.60160179e+00 ... -4.98941290e-12\n",
      "   2.63592491e-12 -2.90142707e-13]\n",
      " [-6.22118565e-01  1.04360241e+00  1.04274121e+00 ... -8.59212775e-01\n",
      "  -2.46031587e-01  2.44635873e-02]\n",
      " ...\n",
      " [ 5.63029444e-01  1.04360241e+00  1.04274121e+00 ... -1.93109791e-01\n",
      "  -2.46031587e-01  2.44635873e-02]\n",
      " [ 1.88772178e-01  1.61711904e+00  1.64459107e+00 ... -4.98941290e-12\n",
      "   2.63592491e-12  2.44635873e-02]\n",
      " [ 1.26395967e-01  7.56844099e-01  7.33218431e-01 ... -4.98941290e-12\n",
      "   2.63592491e-12  2.44635873e-02]]\n"
     ]
    }
   ],
   "source": [
    "x_train_std, _, _, = standardize(x_train_w_mean)\n",
    "print(x_train_std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(328135, 321)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "print(np.shape(x_train_std))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 91.17 % minus ones.\n",
      "\n",
      "There are 8.83 % ones.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "### Count the amount of incidents\n",
    "\n",
    "minus_ones = np.sum((y_train == -1))\n",
    "\n",
    "ones = np.sum(( y_train == 1))\n",
    "print(f\"There are {100*minus_ones/len(y_train):.2f} % minus ones.\\n\")\n",
    "print(f\"There are {100*ones/len(y_train):.2f} % ones.\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "mean_squared_error_sgd() got an unexpected keyword argument 'batch_size'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\jonas\\EPFL\\MA2\\ML_Project1\\run.ipynb Cell 13\u001b[0m line \u001b[0;36m2\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/jonas/EPFL/MA2/ML_Project1/run.ipynb#X15sZmlsZQ%3D%3D?line=18'>19</a>\u001b[0m \u001b[39m#1) mean_squared_error_gd \u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/jonas/EPFL/MA2/ML_Project1/run.ipynb#X15sZmlsZQ%3D%3D?line=19'>20</a>\u001b[0m \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(max_iters):\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/jonas/EPFL/MA2/ML_Project1/run.ipynb#X15sZmlsZQ%3D%3D?line=20'>21</a>\u001b[0m \n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/jonas/EPFL/MA2/ML_Project1/run.ipynb#X15sZmlsZQ%3D%3D?line=21'>22</a>\u001b[0m     \u001b[39m#1) mean_squared_error_gd\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/jonas/EPFL/MA2/ML_Project1/run.ipynb#X15sZmlsZQ%3D%3D?line=22'>23</a>\u001b[0m     \u001b[39m#w, loss = mean_squared_error_gd(y, tx, w, max_iters, gamma)\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/jonas/EPFL/MA2/ML_Project1/run.ipynb#X15sZmlsZQ%3D%3D?line=23'>24</a>\u001b[0m \n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/jonas/EPFL/MA2/ML_Project1/run.ipynb#X15sZmlsZQ%3D%3D?line=24'>25</a>\u001b[0m     \u001b[39m#2) mean_squared_error_sgd\u001b[39;00m\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/jonas/EPFL/MA2/ML_Project1/run.ipynb#X15sZmlsZQ%3D%3D?line=25'>26</a>\u001b[0m     w, loss \u001b[39m=\u001b[39m mean_squared_error_sgd(y, tx, w, max_iters, gamma,  batch_size\u001b[39m=\u001b[39;49m\u001b[39m128\u001b[39;49m, num_batches\u001b[39m=\u001b[39;49m\u001b[39m16\u001b[39;49m) \n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/jonas/EPFL/MA2/ML_Project1/run.ipynb#X15sZmlsZQ%3D%3D?line=27'>28</a>\u001b[0m     \u001b[39m#3) least_squares\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/jonas/EPFL/MA2/ML_Project1/run.ipynb#X15sZmlsZQ%3D%3D?line=28'>29</a>\u001b[0m     \u001b[39m#w, loss = least_squares(y, tx)  # change input data here, matrix is not invertible[10, 12, 14/15/20/69]\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/jonas/EPFL/MA2/ML_Project1/run.ipynb#X15sZmlsZQ%3D%3D?line=30'>31</a>\u001b[0m     \u001b[39m\"\"\" #4) ridge_regression\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/jonas/EPFL/MA2/ML_Project1/run.ipynb#X15sZmlsZQ%3D%3D?line=31'>32</a>\u001b[0m \u001b[39m    w, loss = ridge_regression(y, tx, lambda_)\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/jonas/EPFL/MA2/ML_Project1/run.ipynb#X15sZmlsZQ%3D%3D?line=32'>33</a>\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/jonas/EPFL/MA2/ML_Project1/run.ipynb#X15sZmlsZQ%3D%3D?line=36'>37</a>\u001b[0m \u001b[39m    #6) reg_logistic_regression\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/jonas/EPFL/MA2/ML_Project1/run.ipynb#X15sZmlsZQ%3D%3D?line=37'>38</a>\u001b[0m \u001b[39m    w, loss = reg_logistic_regression(y, tx, w, max_iters, gamma, lambda_) \"\"\"\u001b[39;00m\n",
      "\u001b[1;31mTypeError\u001b[0m: mean_squared_error_sgd() got an unexpected keyword argument 'batch_size'"
     ]
    }
   ],
   "source": [
    "tx = x_train_std[:, [10, 42, 69]] # change input data here\n",
    "y = y_train[:] # change target value here\n",
    "y = y.reshape(-1, 1)\n",
    "\n",
    "\n",
    "\n",
    "w_s=[]\n",
    "losses=[]\n",
    "w = np.full((tx.shape[1],1), 1e-16) \n",
    "\n",
    "max_iters=50\n",
    "accs=[]\n",
    "precs=[]\n",
    "recs=[]\n",
    "F1s=[]\n",
    "batch_size = 1 \n",
    "lambda_ = 1e-3\n",
    "gamma = 0.1\n",
    "#1) mean_squared_error_gd \n",
    "for i in range(max_iters):\n",
    "\n",
    "    #1) mean_squared_error_gd\n",
    "    #w, loss = mean_squared_error_gd(y, tx, w, max_iters, gamma)\n",
    "\n",
    "    #2) mean_squared_error_sgd\n",
    "    w, loss = mean_squared_error_sgd(y, tx, w, max_iters, gamma,  batch_size=128, num_batches=16) \n",
    "\n",
    "    #3) least_squares\n",
    "    #w, loss = least_squares(y, tx)  # change input data here, matrix is not invertible[10, 12, 14/15/20/69]\n",
    "\n",
    "    \"\"\" #4) ridge_regression\n",
    "    w, loss = ridge_regression(y, tx, lambda_)\n",
    "\n",
    "    #5) logistic_regression\n",
    "    w, loss = logistic_regression(y, tx, w, max_iters, gamma)\n",
    "\n",
    "    #6) reg_logistic_regression\n",
    "    w, loss = reg_logistic_regression(y, tx, w, max_iters, gamma, lambda_) \"\"\"\n",
    " \n",
    "    losses.append(loss)\n",
    "\n",
    " \n",
    "    y_pred=tx.dot(w)\n",
    "    y_pred = compute_sigmoid(y_pred)\n",
    "    y_pred[y_pred>0] = 1\n",
    "    y_pred[y_pred<=0] = -1\n",
    "    \n",
    "    TP = 0\n",
    "    FP = 0\n",
    "    TN = 0\n",
    "    FN = 0\n",
    "    for pred in range(len(y_pred)):\n",
    "        if (y_pred[pred] == 1 and y[pred] == 1):\n",
    "            TP+=1\n",
    "        elif (y_pred[pred] == 1 and y[pred] == -1):\n",
    "            FP+=1\n",
    "        elif (y_pred[pred] == -1 and y[pred] == 1):\n",
    "            FN+=1\n",
    "        else :\n",
    "            TN+=1\n",
    "    acc = (TP+TN)/len(y_pred)\n",
    "    if TP + FP == 0:\n",
    "        prec = 0  # Avoid division by zero\n",
    "    else:\n",
    "        prec = TP / (TP + FP)\n",
    "\n",
    "\n",
    "    if TP + FN == 0:\n",
    "        rec = 0  # Avoid division by zero\n",
    "    else:\n",
    "        rec = TP / (TP + FN)\n",
    "\n",
    "\n",
    "    if prec + rec == 0:\n",
    "        F1score = 0  # Avoid division by zero\n",
    "    else:\n",
    "        F1score = 2 * prec * rec / (prec + rec)\n",
    "\n",
    "\n",
    "    if acc > 0.75 :\n",
    "        w_s.append(w)\n",
    "\n",
    "    accs.append(acc)\n",
    "    precs.append(prec)\n",
    "    recs.append(recs)\n",
    "    F1s.append(F1score)\n",
    "    conf_matrix = np.array([[TP, FP], [FN, TN]])\n",
    "        \n",
    "w_s = np.asarray(w_s)\n",
    "print(\"lambda = \",lambda_,\"| Accuracy moyenne :\",np.mean(accs),\"| Acc>0.75 :\",w_s.shape[0])\n",
    "print(accs)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure()\n",
    "plt.plot(np.linspace(0, max_iters, max_iters), accs)\n",
    "plt.xlabel(\"Iterations\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test = handle_nan_values(x_test, delete_nan_columns=False)\n",
    "x_test, _, _  = standardize(x_test)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\n",
      "[[-0.04222617]\n",
      " [-0.0423904 ]\n",
      " [ 0.23668699]\n",
      " ...\n",
      " [ 0.23668699]\n",
      " [ 0.37556434]\n",
      " [-0.04222617]]\n"
     ]
    }
   ],
   "source": [
    "### Generate first submission\n",
    "\n",
    "y_test = x_test[:, [10, 42, 69]].dot(w)\n",
    "\n",
    "logical_matrix = np.isnan(y_test)\n",
    "nan_per_columns = np.sum(logical_matrix, axis=0)\n",
    "print(nan_per_columns)\n",
    "print(y_test)\n",
    "y_test = compute_sigmoid(y_test)\n",
    "\n",
    "y_test[y_test>0] = 1\n",
    "y_test[y_test<=0] = -1\n",
    "\n",
    "\n",
    "\n",
    "helpers.create_csv_submission(test_ids, y_test, \"AI_crowd_submission\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Local test accuracy of mean_squared_error_gd is -127.135\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jonas\\EPFL\\MA2\\ML_Project1\\functions.py:22: RuntimeWarning: overflow encountered in exp\n",
      "  sigmoid = 1/(1+np.exp(-x))\n",
      "c:\\Users\\jonas\\EPFL\\MA2\\ML_Project1\\functions.py:70: RuntimeWarning: overflow encountered in exp\n",
      "  loss = np.sum(np.log(1 + np.exp(pred)) - y * pred)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lambda =  0.001 | Accuracy moyenne : 0.9744 | Acc>0.75 : 1\n",
      "[0.9744]\n"
     ]
    }
   ],
   "source": [
    "changed_data = False # used to make least_squares work\n",
    "\n",
    "if changed_data:\n",
    "    tx = x_train_std[:1000, [10, 42, 69]] # change input data here\n",
    "    y = y_train[:1000] # change target value here\n",
    "    y = y.reshape(-1, 1)\n",
    "else:\n",
    "    # divide dataset into train and test data in order to test prediction on other data than was used for testing\n",
    "    train_data_size = 200000\n",
    "    local_test_data_size = y_train.shape[0] - train_data_size\n",
    "    total_data_size = y.shape[0]\n",
    "\n",
    "    tx = x_train_std[:train_data_size, :]\n",
    "    y = y_train[:train_data_size]\n",
    "    x_local_test = x_train_std[train_data_size:, :]\n",
    "    y_local_test = y_train[train_data_size:]\n",
    "\n",
    "    y = y.reshape(-1, 1)\n",
    "    y_local_test = y_local_test.reshape(-1, 1)\n",
    "\n",
    "w_s=[]\n",
    "losses=[]\n",
    "w = np.full((tx.shape[1],1), 1e-16) \n",
    "\n",
    "max_iters=100\n",
    "accs=[]\n",
    "precs=[]\n",
    "recs=[]\n",
    "F1s=[]\n",
    "batch_size = 1 \n",
    "lambda_ = 1e-3\n",
    "gamma = 0.1\n",
    "\n",
    "gammas = np.arange(0.005, 0.3, 0.05)\n",
    "lambdas = np.arange(0.00005, 0.003, 0.0005)\n",
    "\n",
    "# Test different gammas and lambdas\n",
    "#for gamma in gammas:\n",
    "#    for lambda_ in lambdas:\n",
    "\n",
    "\n",
    "#1) mean_squared_error_gd\n",
    "w, loss = mean_squared_error_gd(y, tx, w, max_iters, gamma)\n",
    "losses.append(loss)\n",
    "y_local_pred = predict_y(w, x_local_test)\n",
    "local_test_accuracy = ( total_data_size - np.sum(y_local_test != y_local_pred) ) / total_data_size\n",
    "print(\"Local test accuracy of mean_squared_error_gd is\", local_test_accuracy)\n",
    "\n",
    "#2) mean_squared_error_sgd\n",
    "w, loss = mean_squared_error_sgd(y, tx, w, max_iters, gamma)\n",
    "losses.append(loss)\n",
    "\n",
    "#3) least_squares\n",
    "if changed_data:\n",
    "    w, loss = least_squares(y, tx)  # change input data here, matrix is not invertible[10, 12, 14/15/20/69]\n",
    "\n",
    "#4) ridge_regression\n",
    "w, loss = ridge_regression(y, tx, lambda_)\n",
    "losses.append(loss)\n",
    "\n",
    "#5) logistic_regression\n",
    "w, loss = logistic_regression(y, tx, w, max_iters, gamma)\n",
    "losses.append(loss)\n",
    "\n",
    "#6) reg_logistic_regression\n",
    "w, loss = reg_logistic_regression(y, tx, w, max_iters, gamma, lambda_)\n",
    "losses.append(loss)\n",
    "\n",
    "\n",
    "y_pred=tx.dot(w)\n",
    "y_pred = compute_sigmoid(y_pred)\n",
    "y_pred[y_pred>0.5] = 1\n",
    "y_pred[y_pred<=0.5] = 0\n",
    "\n",
    "TP = 0\n",
    "FP = 0\n",
    "TN = 0\n",
    "FN = 0\n",
    "for pred in range(len(y_pred)):\n",
    "    if (y_pred[pred] == 1 and y[pred] == 1):\n",
    "        TP+=1\n",
    "    elif (y_pred[pred] == 1 and y[pred] == 0):\n",
    "        FP+=1\n",
    "    elif (y_pred[pred] == 0 and y[pred] == 1):\n",
    "        FN+=1\n",
    "    else :\n",
    "        TN+=1\n",
    "acc = (TP+TN)/len(y_pred)\n",
    "if TP + FP == 0:\n",
    "    prec = 0  # Avoid division by zero\n",
    "else:\n",
    "    prec = TP / (TP + FP)\n",
    "\n",
    "\n",
    "if TP + FN == 0:\n",
    "    rec = 0  # Avoid division by zero\n",
    "else:\n",
    "    rec = TP / (TP + FN)\n",
    "\n",
    "\n",
    "if prec + rec == 0:\n",
    "    F1score = 0  # Avoid division by zero\n",
    "else:\n",
    "    F1score = 2 * prec * rec / (prec + rec)\n",
    "\n",
    "\n",
    "if acc > 0.75 :\n",
    "    w_s.append(w)\n",
    "\n",
    "accs.append(acc)\n",
    "precs.append(prec)\n",
    "recs.append(recs)\n",
    "F1s.append(F1score)\n",
    "conf_matrix = np.array([[TP, FP], [FN, TN]])\n",
    "        \n",
    "w_s = np.asarray(w_s)\n",
    "print(\"lambda = \",lambda_,\"| Accuracy moyenne :\",np.mean(accs),\"| Acc>0.75 :\",w_s.shape[0])\n",
    "print(accs)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "x and y must have same first dimension, but have shapes (100,) and (1,)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\jonas\\EPFL\\MA2\\ML_Project1\\run.ipynb Cell 15\u001b[0m line \u001b[0;36m2\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/jonas/EPFL/MA2/ML_Project1/run.ipynb#X20sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m plt\u001b[39m.\u001b[39mfigure()\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/jonas/EPFL/MA2/ML_Project1/run.ipynb#X20sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m plt\u001b[39m.\u001b[39;49mplot(np\u001b[39m.\u001b[39;49mlinspace(\u001b[39m0\u001b[39;49m, max_iters, max_iters), accs)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/jonas/EPFL/MA2/ML_Project1/run.ipynb#X20sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m plt\u001b[39m.\u001b[39mxlabel(\u001b[39m\"\u001b[39m\u001b[39mIterations\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/jonas/EPFL/MA2/ML_Project1/run.ipynb#X20sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m plt\u001b[39m.\u001b[39mylabel(\u001b[39m\"\u001b[39m\u001b[39mAccuracy\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\jonas\\anaconda3\\envs\\CIVIL-459\\lib\\site-packages\\matplotlib\\pyplot.py:2785\u001b[0m, in \u001b[0;36mplot\u001b[1;34m(scalex, scaley, data, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2783\u001b[0m \u001b[39m@_copy_docstring_and_deprecators\u001b[39m(Axes\u001b[39m.\u001b[39mplot)\n\u001b[0;32m   2784\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mplot\u001b[39m(\u001b[39m*\u001b[39margs, scalex\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m, scaley\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m, data\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m-> 2785\u001b[0m     \u001b[39mreturn\u001b[39;00m gca()\u001b[39m.\u001b[39mplot(\n\u001b[0;32m   2786\u001b[0m         \u001b[39m*\u001b[39margs, scalex\u001b[39m=\u001b[39mscalex, scaley\u001b[39m=\u001b[39mscaley,\n\u001b[0;32m   2787\u001b[0m         \u001b[39m*\u001b[39m\u001b[39m*\u001b[39m({\u001b[39m\"\u001b[39m\u001b[39mdata\u001b[39m\u001b[39m\"\u001b[39m: data} \u001b[39mif\u001b[39;00m data \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m {}), \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\jonas\\anaconda3\\envs\\CIVIL-459\\lib\\site-packages\\matplotlib\\axes\\_axes.py:1688\u001b[0m, in \u001b[0;36mAxes.plot\u001b[1;34m(self, scalex, scaley, data, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1445\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m   1446\u001b[0m \u001b[39mPlot y versus x as lines and/or markers.\u001b[39;00m\n\u001b[0;32m   1447\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1685\u001b[0m \u001b[39m(``'green'``) or hex strings (``'#008000'``).\u001b[39;00m\n\u001b[0;32m   1686\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m   1687\u001b[0m kwargs \u001b[39m=\u001b[39m cbook\u001b[39m.\u001b[39mnormalize_kwargs(kwargs, mlines\u001b[39m.\u001b[39mLine2D)\n\u001b[1;32m-> 1688\u001b[0m lines \u001b[39m=\u001b[39m [\u001b[39m*\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_get_lines(\u001b[39m*\u001b[39margs, data\u001b[39m=\u001b[39mdata, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)]\n\u001b[0;32m   1689\u001b[0m \u001b[39mfor\u001b[39;00m line \u001b[39min\u001b[39;00m lines:\n\u001b[0;32m   1690\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39madd_line(line)\n",
      "File \u001b[1;32mc:\\Users\\jonas\\anaconda3\\envs\\CIVIL-459\\lib\\site-packages\\matplotlib\\axes\\_base.py:311\u001b[0m, in \u001b[0;36m_process_plot_var_args.__call__\u001b[1;34m(self, data, *args, **kwargs)\u001b[0m\n\u001b[0;32m    309\u001b[0m     this \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m args[\u001b[39m0\u001b[39m],\n\u001b[0;32m    310\u001b[0m     args \u001b[39m=\u001b[39m args[\u001b[39m1\u001b[39m:]\n\u001b[1;32m--> 311\u001b[0m \u001b[39myield from\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_plot_args(\n\u001b[0;32m    312\u001b[0m     this, kwargs, ambiguous_fmt_datakey\u001b[39m=\u001b[39;49mambiguous_fmt_datakey)\n",
      "File \u001b[1;32mc:\\Users\\jonas\\anaconda3\\envs\\CIVIL-459\\lib\\site-packages\\matplotlib\\axes\\_base.py:504\u001b[0m, in \u001b[0;36m_process_plot_var_args._plot_args\u001b[1;34m(self, tup, kwargs, return_kwargs, ambiguous_fmt_datakey)\u001b[0m\n\u001b[0;32m    501\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39maxes\u001b[39m.\u001b[39myaxis\u001b[39m.\u001b[39mupdate_units(y)\n\u001b[0;32m    503\u001b[0m \u001b[39mif\u001b[39;00m x\u001b[39m.\u001b[39mshape[\u001b[39m0\u001b[39m] \u001b[39m!=\u001b[39m y\u001b[39m.\u001b[39mshape[\u001b[39m0\u001b[39m]:\n\u001b[1;32m--> 504\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mx and y must have same first dimension, but \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    505\u001b[0m                      \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mhave shapes \u001b[39m\u001b[39m{\u001b[39;00mx\u001b[39m.\u001b[39mshape\u001b[39m}\u001b[39;00m\u001b[39m and \u001b[39m\u001b[39m{\u001b[39;00my\u001b[39m.\u001b[39mshape\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[0;32m    506\u001b[0m \u001b[39mif\u001b[39;00m x\u001b[39m.\u001b[39mndim \u001b[39m>\u001b[39m \u001b[39m2\u001b[39m \u001b[39mor\u001b[39;00m y\u001b[39m.\u001b[39mndim \u001b[39m>\u001b[39m \u001b[39m2\u001b[39m:\n\u001b[0;32m    507\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mx and y can be no greater than 2D, but have \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    508\u001b[0m                      \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mshapes \u001b[39m\u001b[39m{\u001b[39;00mx\u001b[39m.\u001b[39mshape\u001b[39m}\u001b[39;00m\u001b[39m and \u001b[39m\u001b[39m{\u001b[39;00my\u001b[39m.\u001b[39mshape\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n",
      "\u001b[1;31mValueError\u001b[0m: x and y must have same first dimension, but have shapes (100,) and (1,)"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAi4AAAGiCAYAAADA0E3hAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy88F64QAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAcu0lEQVR4nO3db2yV5f348U9paaturRG0FkEEpxMl6mgDo6wandag0ZBskcVF1GliszmETqeMRYYxaXTRfXUKbgoaE3REReeDztEHG1Zxf2DFGCFxEWZBW0kxtqhbGXD/Hhj6W9fiOLV/uNrXK7kfnMv7Puc6uazn7X2fP3lZlmUBAJCAMcM9AQCAIyVcAIBkCBcAIBnCBQBIhnABAJIhXACAZAgXACAZwgUASIZwAQCSIVwAgGTkHC6vvPJKXHnllTFhwoTIy8uLF1988X8es2HDhqioqIji4uKYOnVqPProo/2ZKwAwyuUcLp988kmcd9558fDDDx/R/jt27IjLL788qquro7m5OX7yk5/EwoUL4/nnn895sgDA6Jb3RX5kMS8vL1544YWYN2/eYfe544474qWXXopt27Z1j9XW1sYbb7wRr7/+en8fGgAYhQoG+wFef/31qKmp6TF22WWXxapVq+Lf//53jB07ttcxXV1d0dXV1X374MGD8eGHH8a4ceMiLy9vsKcMAAyALMti7969MWHChBgzZmDeVjvo4dLW1hZlZWU9xsrKymL//v3R3t4e5eXlvY6pr6+P5cuXD/bUAIAhsHPnzpg4ceKA3Negh0tE9DpLcujq1OHOnixZsiTq6uq6b3d0dMSpp54aO3fujJKSksGbKAAwYDo7O2PSpEnx5S9/ecDuc9DD5eSTT462trYeY7t3746CgoIYN25cn8cUFRVFUVFRr/GSkhLhAgCJGci3eQz697jMnj07Ghsbe4ytX78+Kisr+3x/CwDA4eQcLh9//HFs2bIltmzZEhGffdx5y5Yt0dLSEhGfXeZZsGBB9/61tbXx7rvvRl1dXWzbti1Wr14dq1atittuu21gngEAMGrkfKlo06ZNcdFFF3XfPvRelOuuuy6efPLJaG1t7Y6YiIgpU6ZEQ0NDLF68OB555JGYMGFCPPTQQ/Gtb31rAKYPAIwmX+h7XIZKZ2dnlJaWRkdHh/e4AEAiBuP1228VAQDJEC4AQDKECwCQDOECACRDuAAAyRAuAEAyhAsAkAzhAgAkQ7gAAMkQLgBAMoQLAJAM4QIAJEO4AADJEC4AQDKECwCQDOECACRDuAAAyRAuAEAyhAsAkAzhAgAkQ7gAAMkQLgBAMoQLAJAM4QIAJEO4AADJEC4AQDKECwCQDOECACRDuAAAyRAuAEAyhAsAkAzhAgAkQ7gAAMkQLgBAMoQLAJAM4QIAJEO4AADJEC4AQDKECwCQDOECACRDuAAAyRAuAEAyhAsAkAzhAgAkQ7gAAMkQLgBAMoQLAJAM4QIAJEO4AADJEC4AQDKECwCQDOECACRDuAAAyRAuAEAyhAsAkAzhAgAkQ7gAAMkQLgBAMoQLAJAM4QIAJEO4AADJEC4AQDKECwCQjH6Fy4oVK2LKlClRXFwcFRUV0dTU9Ln7r1mzJs4777w49thjo7y8PG644YbYs2dPvyYMAIxeOYfL2rVrY9GiRbF06dJobm6O6urqmDt3brS0tPS5/6uvvhoLFiyIG2+8Md5666149tln469//WvcdNNNX3jyAMDoknO4PPDAA3HjjTfGTTfdFNOmTYv/+7//i0mTJsXKlSv73P9Pf/pTnHbaabFw4cKYMmVKfOMb34ibb745Nm3a9IUnDwCMLjmFy759+2Lz5s1RU1PTY7ympiY2btzY5zFVVVWxa9euaGhoiCzL4oMPPojnnnsurrjiisM+TldXV3R2dvbYAAByCpf29vY4cOBAlJWV9RgvKyuLtra2Po+pqqqKNWvWxPz586OwsDBOPvnkOP744+OXv/zlYR+nvr4+SktLu7dJkyblMk0AYITq15tz8/LyetzOsqzX2CFbt26NhQsXxl133RWbN2+Ol19+OXbs2BG1tbWHvf8lS5ZER0dH97Zz587+TBMAGGEKctl5/PjxkZ+f3+vsyu7du3udhTmkvr4+5syZE7fffntERJx77rlx3HHHRXV1ddxzzz1RXl7e65iioqIoKirKZWoAwCiQ0xmXwsLCqKioiMbGxh7jjY2NUVVV1ecxn376aYwZ0/Nh8vPzI+KzMzUAAEcq50tFdXV18fjjj8fq1atj27ZtsXjx4mhpaem+9LNkyZJYsGBB9/5XXnllrFu3LlauXBnbt2+P1157LRYuXBgzZ86MCRMmDNwzAQBGvJwuFUVEzJ8/P/bs2RN33313tLa2xvTp06OhoSEmT54cERGtra09vtPl+uuvj71798bDDz8cP/rRj+L444+Piy++OO69996BexYAwKiQlyVwvaazszNKS0ujo6MjSkpKhns6AMARGIzXb79VBAAkQ7gAAMkQLgBAMoQLAJAM4QIAJEO4AADJEC4AQDKECwCQDOECACRDuAAAyRAuAEAyhAsAkAzhAgAkQ7gAAMkQLgBAMoQLAJAM4QIAJEO4AADJEC4AQDKECwCQDOECACRDuAAAyRAuAEAyhAsAkAzhAgAkQ7gAAMkQLgBAMoQLAJAM4QIAJEO4AADJEC4AQDKECwCQDOECACRDuAAAyRAuAEAyhAsAkAzhAgAkQ7gAAMkQLgBAMoQLAJAM4QIAJEO4AADJEC4AQDKECwCQDOECACRDuAAAyRAuAEAyhAsAkAzhAgAkQ7gAAMkQLgBAMoQLAJAM4QIAJEO4AADJEC4AQDKECwCQDOECACRDuAAAyRAuAEAyhAsAkAzhAgAkQ7gAAMkQLgBAMvoVLitWrIgpU6ZEcXFxVFRURFNT0+fu39XVFUuXLo3JkydHUVFRnH766bF69ep+TRgAGL0Kcj1g7dq1sWjRolixYkXMmTMnfvWrX8XcuXNj69atceqpp/Z5zNVXXx0ffPBBrFq1Kr7yla/E7t27Y//+/V948gDA6JKXZVmWywGzZs2KGTNmxMqVK7vHpk2bFvPmzYv6+vpe+7/88svxne98J7Zv3x4nnHBCvybZ2dkZpaWl0dHRESUlJf26DwBgaA3G63dOl4r27dsXmzdvjpqamh7jNTU1sXHjxj6Peemll6KysjLuu+++OOWUU+LMM8+M2267Lf75z38e9nG6urqis7OzxwYAkNOlovb29jhw4ECUlZX1GC8rK4u2trY+j9m+fXu8+uqrUVxcHC+88EK0t7fH97///fjwww8P+z6X+vr6WL58eS5TAwBGgX69OTcvL6/H7SzLeo0dcvDgwcjLy4s1a9bEzJkz4/LLL48HHnggnnzyycOedVmyZEl0dHR0bzt37uzPNAGAESanMy7jx4+P/Pz8XmdXdu/e3esszCHl5eVxyimnRGlpaffYtGnTIsuy2LVrV5xxxhm9jikqKoqioqJcpgYAjAI5nXEpLCyMioqKaGxs7DHe2NgYVVVVfR4zZ86ceP/99+Pjjz/uHnv77bdjzJgxMXHixH5MGQAYrXK+VFRXVxePP/54rF69OrZt2xaLFy+OlpaWqK2tjYjPLvMsWLCge/9rrrkmxo0bFzfccENs3bo1Xnnllbj99tvje9/7XhxzzDED90wAgBEv5+9xmT9/fuzZsyfuvvvuaG1tjenTp0dDQ0NMnjw5IiJaW1ujpaWle/8vfelL0djYGD/84Q+jsrIyxo0bF1dffXXcc889A/csAIBRIefvcRkOvscFANIz7N/jAgAwnIQLAJAM4QIAJEO4AADJEC4AQDKECwCQDOECACRDuAAAyRAuAEAyhAsAkAzhAgAkQ7gAAMkQLgBAMoQLAJAM4QIAJEO4AADJEC4AQDKECwCQDOECACRDuAAAyRAuAEAyhAsAkAzhAgAkQ7gAAMkQLgBAMoQLAJAM4QIAJEO4AADJEC4AQDKECwCQDOECACRDuAAAyRAuAEAyhAsAkAzhAgAkQ7gAAMkQLgBAMoQLAJAM4QIAJEO4AADJEC4AQDKECwCQDOECACRDuAAAyRAuAEAyhAsAkAzhAgAkQ7gAAMkQLgBAMoQLAJAM4QIAJEO4AADJEC4AQDKECwCQDOECACRDuAAAyRAuAEAyhAsAkAzhAgAkQ7gAAMkQLgBAMoQLAJAM4QIAJKNf4bJixYqYMmVKFBcXR0VFRTQ1NR3Rca+99loUFBTE+eef35+HBQBGuZzDZe3atbFo0aJYunRpNDc3R3V1dcydOzdaWlo+97iOjo5YsGBBfPOb3+z3ZAGA0S0vy7IslwNmzZoVM2bMiJUrV3aPTZs2LebNmxf19fWHPe473/lOnHHGGZGfnx8vvvhibNmy5bD7dnV1RVdXV/ftzs7OmDRpUnR0dERJSUku0wUAhklnZ2eUlpYO6Ot3Tmdc9u3bF5s3b46ampoe4zU1NbFx48bDHvfEE0/EO++8E8uWLTuix6mvr4/S0tLubdKkSblMEwAYoXIKl/b29jhw4ECUlZX1GC8rK4u2trY+j/n73/8ed955Z6xZsyYKCgqO6HGWLFkSHR0d3dvOnTtzmSYAMEIdWUn8l7y8vB63syzrNRYRceDAgbjmmmti+fLlceaZZx7x/RcVFUVRUVF/pgYAjGA5hcv48eMjPz+/19mV3bt39zoLExGxd+/e2LRpUzQ3N8ctt9wSEREHDx6MLMuioKAg1q9fHxdffPEXmD4AMJrkdKmosLAwKioqorGxscd4Y2NjVFVV9dq/pKQk3nzzzdiyZUv3VltbG1/96ldjy5YtMWvWrC82ewBgVMn5UlFdXV1ce+21UVlZGbNnz45f//rX0dLSErW1tRHx2ftT3nvvvXjqqadizJgxMX369B7Hn3TSSVFcXNxrHADgf8k5XObPnx979uyJu+++O1pbW2P69OnR0NAQkydPjoiI1tbW//mdLgAA/ZHz97gMh8H4HDgAMLiG/XtcAACGk3ABAJIhXACAZAgXACAZwgUASIZwAQCSIVwAgGQIFwAgGcIFAEiGcAEAkiFcAIBkCBcAIBnCBQBIhnABAJIhXACAZAgXACAZwgUASIZwAQCSIVwAgGQIFwAgGcIFAEiGcAEAkiFcAIBkCBcAIBnCBQBIhnABAJIhXACAZAgXACAZwgUASIZwAQCSIVwAgGQIFwAgGcIFAEiGcAEAkiFcAIBkCBcAIBnCBQBIhnABAJIhXACAZAgXACAZwgUASIZwAQCSIVwAgGQIFwAgGcIFAEiGcAEAkiFcAIBkCBcAIBnCBQBIhnABAJIhXACAZAgXACAZwgUASIZwAQCSIVwAgGQIFwAgGcIFAEiGcAEAkiFcAIBkCBcAIBnCBQBIhnABAJIhXACAZPQrXFasWBFTpkyJ4uLiqKioiKampsPuu27durj00kvjxBNPjJKSkpg9e3b8/ve/7/eEAYDRK+dwWbt2bSxatCiWLl0azc3NUV1dHXPnzo2WlpY+93/llVfi0ksvjYaGhti8eXNcdNFFceWVV0Zzc/MXnjwAMLrkZVmW5XLArFmzYsaMGbFy5crusWnTpsW8efOivr7+iO7jnHPOifnz58ddd93V5z/v6uqKrq6u7tudnZ0xadKk6OjoiJKSklymCwAMk87OzigtLR3Q1++czrjs27cvNm/eHDU1NT3Ga2pqYuPGjUd0HwcPHoy9e/fGCSeccNh96uvro7S0tHubNGlSLtMEAEaonMKlvb09Dhw4EGVlZT3Gy8rKoq2t7Yju4/77749PPvkkrr766sPus2TJkujo6Ojedu7cmcs0AYARqqA/B+Xl5fW4nWVZr7G+PPPMM/Gzn/0sfvvb38ZJJ5102P2KioqiqKioP1MDAEawnMJl/PjxkZ+f3+vsyu7du3udhflva9eujRtvvDGeffbZuOSSS3KfKQAw6uV0qaiwsDAqKiqisbGxx3hjY2NUVVUd9rhnnnkmrr/++nj66afjiiuu6N9MAYBRL+dLRXV1dXHttddGZWVlzJ49O379619HS0tL1NbWRsRn709577334qmnnoqIz6JlwYIF8eCDD8bXv/717rM1xxxzTJSWlg7gUwEARrqcw2X+/PmxZ8+euPvuu6O1tTWmT58eDQ0NMXny5IiIaG1t7fGdLr/61a9i//798YMf/CB+8IMfdI9fd9118eSTT37xZwAAjBo5f4/LcBiMz4EDAINr2L/HBQBgOAkXACAZwgUASIZwAQCSIVwAgGQIFwAgGcIFAEiGcAEAkiFcAIBkCBcAIBnCBQBIhnABAJIhXACAZAgXACAZwgUASIZwAQCSIVwAgGQIFwAgGcIFAEiGcAEAkiFcAIBkCBcAIBnCBQBIhnABAJIhXACAZAgXACAZwgUASIZwAQCSIVwAgGQIFwAgGcIFAEiGcAEAkiFcAIBkCBcAIBnCBQBIhnABAJIhXACAZAgXACAZwgUASIZwAQCSIVwAgGQIFwAgGcIFAEiGcAEAkiFcAIBkCBcAIBnCBQBIhnABAJIhXACAZAgXACAZwgUASIZwAQCSIVwAgGQIFwAgGcIFAEiGcAEAkiFcAIBkCBcAIBnCBQBIhnABAJIhXACAZAgXACAZwgUASEa/wmXFihUxZcqUKC4ujoqKimhqavrc/Tds2BAVFRVRXFwcU6dOjUcffbRfkwUARrecw2Xt2rWxaNGiWLp0aTQ3N0d1dXXMnTs3Wlpa+tx/x44dcfnll0d1dXU0NzfHT37yk1i4cGE8//zzX3jyAMDokpdlWZbLAbNmzYoZM2bEypUru8emTZsW8+bNi/r6+l7733HHHfHSSy/Ftm3busdqa2vjjTfeiNdff73Px+jq6oqurq7u2x0dHXHqqafGzp07o6SkJJfpAgDDpLOzMyZNmhQfffRRlJaWDsydZjno6urK8vPzs3Xr1vUYX7hwYXbBBRf0eUx1dXW2cOHCHmPr1q3LCgoKsn379vV5zLJly7KIsNlsNpvNNgK2d955J5fc+FwFkYP29vY4cOBAlJWV9RgvKyuLtra2Po9pa2vrc//9+/dHe3t7lJeX9zpmyZIlUVdX1337o48+ismTJ0dLS8vAFRv9cqienf0aftbi6GEtji7W4+hx6IrJCSecMGD3mVO4HJKXl9fjdpZlvcb+1/59jR9SVFQURUVFvcZLS0v9S3iUKCkpsRZHCWtx9LAWRxfrcfQYM2bgPsSc0z2NHz8+8vPze51d2b17d6+zKoecfPLJfe5fUFAQ48aNy3G6AMBollO4FBYWRkVFRTQ2NvYYb2xsjKqqqj6PmT17dq/9169fH5WVlTF27NgcpwsAjGY5n7upq6uLxx9/PFavXh3btm2LxYsXR0tLS9TW1kbEZ+9PWbBgQff+tbW18e6770ZdXV1s27YtVq9eHatWrYrbbrvtiB+zqKgoli1b1uflI4aWtTh6WIujh7U4uliPo8dgrEXOH4eO+OwL6O67775obW2N6dOnxy9+8Yu44IILIiLi+uuvj3/84x/xxz/+sXv/DRs2xOLFi+Ott96KCRMmxB133NEdOgAAR6pf4QIAMBz8VhEAkAzhAgAkQ7gAAMkQLgBAMo6acFmxYkVMmTIliouLo6KiIpqamj53/w0bNkRFRUUUFxfH1KlT49FHHx2imY58uazFunXr4tJLL40TTzwxSkpKYvbs2fH73/9+CGc7suX6d3HIa6+9FgUFBXH++ecP7gRHkVzXoqurK5YuXRqTJ0+OoqKiOP3002P16tVDNNuRLde1WLNmTZx33nlx7LHHRnl5edxwww2xZ8+eIZrtyPXKK6/ElVdeGRMmTIi8vLx48cUX/+cxA/LaPWC/evQF/OY3v8nGjh2bPfbYY9nWrVuzW2+9NTvuuOOyd999t8/9t2/fnh177LHZrbfemm3dujV77LHHsrFjx2bPPffcEM985Ml1LW699dbs3nvvzf7yl79kb7/9drZkyZJs7Nix2d/+9rchnvnIk+taHPLRRx9lU6dOzWpqarLzzjtvaCY7wvVnLa666qps1qxZWWNjY7Zjx47sz3/+c/baa68N4axHplzXoqmpKRszZkz24IMPZtu3b8+ampqyc845J5s3b94Qz3zkaWhoyJYuXZo9//zzWURkL7zwwufuP1Cv3UdFuMycOTOrra3tMXbWWWdld955Z5/7//jHP87OOuusHmM333xz9vWvf33Q5jha5LoWfTn77LOz5cuXD/TURp3+rsX8+fOzn/70p9myZcuEywDJdS1+97vfZaWlpdmePXuGYnqjSq5r8fOf/zybOnVqj7GHHnoomzhx4qDNcTQ6knAZqNfuYb9UtG/fvti8eXPU1NT0GK+pqYmNGzf2eczrr7/ea//LLrssNm3aFP/+978Hba4jXX/W4r8dPHgw9u7dO6C/BDoa9XctnnjiiXjnnXdi2bJlgz3FUaM/a/HSSy9FZWVl3HfffXHKKafEmWeeGbfddlv885//HIopj1j9WYuqqqrYtWtXNDQ0RJZl8cEHH8Rzzz0XV1xxxVBMmf8wUK/d/fp16IHU3t4eBw4c6PUjjWVlZb1+nPGQtra2Pvffv39/tLe3R3l5+aDNdyTrz1r8t/vvvz8++eSTuPrqqwdjiqNGf9bi73//e9x5553R1NQUBQXD/qc9YvRnLbZv3x6vvvpqFBcXxwsvvBDt7e3x/e9/Pz788EPvc/kC+rMWVVVVsWbNmpg/f37861//iv3798dVV10Vv/zlL4diyvyHgXrtHvYzLofk5eX1uJ1lWa+x/7V/X+PkLte1OOSZZ56Jn/3sZ7F27do46aSTBmt6o8qRrsWBAwfimmuuieXLl8eZZ545VNMbVXL5uzh48GDk5eXFmjVrYubMmXH55ZfHAw88EE8++aSzLgMgl7XYunVrLFy4MO66667YvHlzvPzyy7Fjxw4/OzNMBuK1e9j/t2z8+PGRn5/fq5Z3797dq8wOOfnkk/vcv6CgIMaNGzdocx3p+rMWh6xduzZuvPHGePbZZ+OSSy4ZzGmOCrmuxd69e2PTpk3R3Nwct9xyS0R89uKZZVkUFBTE+vXr4+KLLx6SuY80/fm7KC8vj1NOOSVKS0u7x6ZNmxZZlsWuXbvijDPOGNQ5j1T9WYv6+vqYM2dO3H777RERce6558Zxxx0X1dXVcc899zhDP4QG6rV72M+4FBYWRkVFRTQ2NvYYb2xsjKqqqj6PmT17dq/9169fH5WVlTF27NhBm+tI15+1iPjsTMv1118fTz/9tOvGAyTXtSgpKYk333wztmzZ0r3V1tbGV7/61diyZUvMmjVrqKY+4vTn72LOnDnx/vvvx8cff9w99vbbb8eYMWNi4sSJgzrfkaw/a/Hpp5/GmDE9X+ry8/Mj4v//3z5DY8Beu3N6K+8gOfTxtlWrVmVbt27NFi1alB133HHZP/7xjyzLsuzOO+/Mrr322u79D32kavHixdnWrVuzVatW+Tj0AMl1LZ5++umsoKAge+SRR7LW1tbu7aOPPhqupzBi5LoW/82nigZOrmuxd+/ebOLEidm3v/3t7K233so2bNiQnXHGGdlNN900XE9hxMh1LZ544omsoKAgW7FiRfbOO+9kr776alZZWZnNnDlzuJ7CiLF3796subk5a25uziIie+CBB7Lm5ubuj6YP1mv3UREuWZZljzzySDZ58uSssLAwmzFjRrZhw4buf3bddddlF154YY/9//jHP2Zf+9rXssLCwuy0007LVq5cOcQzHrlyWYsLL7wwi4he23XXXTf0Ex+Bcv27+E/CZWDluhbbtm3LLrnkkuyYY47JJk6cmNXV1WWffvrpEM96ZMp1LR566KHs7LPPzo455pisvLw8++53v5vt2rVriGc98vzhD3/43P/+D9Zrd16WOVcGAKRh2N/jAgBwpIQLAJAM4QIAJEO4AADJEC4AQDKECwCQDOECACRDuAAAyRAuAEAyhAsAkAzhAgAk4/8BrQWhjBP+6s8AAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure()\n",
    "plt.plot(np.linspace(0, max_iters, max_iters), accs)\n",
    "plt.xlabel(\"Iterations\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "CIVIL-459",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
