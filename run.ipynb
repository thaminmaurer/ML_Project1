{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CS-433 Machine learning project 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import helpers\n",
    "from functions import *\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x_train = np.genfromtxt(\"data/dataset/x_train.csv\", delimiter=',', skip_header=1)\n",
    "# y_train = np.genfromtxt(\"data/dataset/y_train.csv\", delimiter=',', skip_header=1)\n",
    "# x_test =  np.genfromtxt(\"data/dataset/x_test.csv\", delimiter=',', skip_header=1)\n",
    "x_train, x_test, y_train, train_ids, test_ids = helpers.load_csv_data(\"data/dataset\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2015. 2015. 2015. ... 2015. 2015. 2015.]\n",
      "float64\n",
      "False\n",
      "139415\n"
     ]
    }
   ],
   "source": [
    "print(x_train[:,5])\n",
    "print(x_train[0,5].dtype)\n",
    "print(np.isnan(x_train[0,5]))\n",
    "print(np.sum(np.isnan(x_train[:,10])))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Nan handling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[     0      0      0      0      0      0      0      0      0 139415\n",
      " 139415 328103 139416 139415 328103 139433 139524 139525 188720 188720\n",
      " 188721 188720 327334 188719 189287 192544      2      1      0 159860\n",
      "      0      0      1      1      1 196334      0  43801  43801      0\n",
      "      0 284153      1      0      0      1      0      0      5 285915\n",
      "      0      0      0      0 139415 318245 139415      1      0      3\n",
      "   2471   3207   3946   4407 279663   6933   7743   8293   8728   9149\n",
      "   9432   9862  10541 191379 282510 237369  11007  11765 170906 171212\n",
      " 171522  20738  21567  22468  23149  23759  24502  26205 107829 109141\n",
      " 109407 109690 181261 181400  28647 226907 227043 227197 229088  29911\n",
      "  30600 186763 186001  31022  32080 243418 243561 266689 266689 306425\n",
      " 306426 306428 306429 306429 306629 306429 306430 306430 247299 310302\n",
      " 310320 310346 310367 310392 310403 310450 265347 325762 325769 325769\n",
      " 327339 326264 325775 325777 325777 325780 241493 318477 318489 325051\n",
      " 318505 318515 297518 309300 297543 327354 327645 327907 327907 327648\n",
      " 327648 327649 327793 327650 327650 327362 327618 314089 318284 323942\n",
      " 323941 323942 313550 313560 313564 313572 298044 320046 327036 307336\n",
      " 311136 314308 311142 312277 311151 322950 311321 323914 324421 287897\n",
      " 313435 287921 298973 298976 323261 323267 323272 323272 325495 325498\n",
      " 327539 327956 276513 273642 302161 302172 309175 299744 203924 203990\n",
      " 283588 283743 289046 323324 313056 313066 312994 313007 313014 313018\n",
      " 313027 313032 313044 313055 313067 313074      0     14 142438      0\n",
      "     22      0      0  90436 279532 279532 283603      0 123084      0\n",
      "      0      0      0      0  43801      0      0      0   1883      0\n",
      "      0      0      0      0      0   5438      0      0      0      0\n",
      "  12721  11368  23006  27073  27073      0      0      0      0      0\n",
      "      0      0      0      0      0      0  28366  26927  29382  27893\n",
      "  28958  30593      0      0      0      0  32115  37605      0      0\n",
      "      0      0      0      0      0 108727 112425      0      0 111072\n",
      " 114698 113793 184643 111257 182913 115152 116821  32496      0 117355\n",
      " 119004 112859 113785 117012 111793      0      0      0      0      0\n",
      "      0      0      0   1883   1883   1883      0      0 211378 211378\n",
      "  32080]\n",
      "146965.04361370715\n",
      "(321,)\n",
      "321\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#calculate number number of nan per column\n",
    "logical_matrix = np.isnan(x_train)\n",
    "nan_per_columns = np.sum(logical_matrix, axis=0)\n",
    "print(nan_per_columns)\n",
    "average_nan = np.mean(nan_per_columns)\n",
    "print(average_nan)\n",
    "print(np.shape(nan_per_columns))\n",
    "print(np.shape(x_train)[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# delet the columns with more nan than the average\n",
    "x_train_reduced_features = x_train[:, nan_per_columns <= average_nan]\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(328135, 321)\n"
     ]
    }
   ],
   "source": [
    "print(np.shape(x_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "#replace nan values with the mean:\n",
    "x_train_w_mean = x_train\n",
    "for i in range( np.shape(x_train)[1]):\n",
    "    nan_entries = np.isnan(x_train[:,i])\n",
    "    mean = np.mean(x_train[~nan_entries,i])\n",
    "\n",
    "    nan_entries = np.isnan(x_train[:,i])\n",
    "\n",
    "    x_train_w_mean[nan_entries, i] = mean\n",
    "    \n",
    "logical_matrix = np.isnan(x_train_w_mean)\n",
    "nan_per_columns2 = np.sum(logical_matrix, axis=0)\n",
    "print(nan_per_columns2)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1.43629640e+00  1.33036073e+00  1.31787257e+00 ... -4.98941290e-12\n",
      "   2.63592491e-12  2.44635873e-02]\n",
      " [ 1.88772178e-01  1.61711904e+00  1.60160179e+00 ... -4.98941290e-12\n",
      "   2.63592491e-12 -2.90142707e-13]\n",
      " [-6.22118565e-01  1.04360241e+00  1.04274121e+00 ... -8.59212775e-01\n",
      "  -2.46031587e-01  2.44635873e-02]\n",
      " ...\n",
      " [ 5.63029444e-01  1.04360241e+00  1.04274121e+00 ... -1.93109791e-01\n",
      "  -2.46031587e-01  2.44635873e-02]\n",
      " [ 1.88772178e-01  1.61711904e+00  1.64459107e+00 ... -4.98941290e-12\n",
      "   2.63592491e-12  2.44635873e-02]\n",
      " [ 1.26395967e-01  7.56844099e-01  7.33218431e-01 ... -4.98941290e-12\n",
      "   2.63592491e-12  2.44635873e-02]]\n"
     ]
    }
   ],
   "source": [
    "x_train_std, _, _, = standardize(x_train_w_mean)\n",
    "print(x_train_std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(328135, 321)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "print(np.shape(x_train_std))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 0.00 % zeros.\n",
      "\n",
      "There are 8.83 % ones.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "### Count the amount of incidents\n",
    "\n",
    "zeros = np.sum((y_train == 0))\n",
    "\n",
    "ones = np.sum(( y_train == 1))\n",
    "print(f\"There are {100*zeros/len(y_train):.2f} % zeros.\\n\")\n",
    "print(f\"There are {100*ones/len(y_train):.2f} % ones.\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lambda =  0.001 | Accuracy moyenne : 0.95 | Acc>0.75 : 100\n",
      "[0.95, 0.95, 0.95, 0.95, 0.95, 0.95, 0.95, 0.95, 0.95, 0.95, 0.95, 0.95, 0.95, 0.95, 0.95, 0.95, 0.95, 0.95, 0.95, 0.95, 0.95, 0.95, 0.95, 0.95, 0.95, 0.95, 0.95, 0.95, 0.95, 0.95, 0.95, 0.95, 0.95, 0.95, 0.95, 0.95, 0.95, 0.95, 0.95, 0.95, 0.95, 0.95, 0.95, 0.95, 0.95, 0.95, 0.95, 0.95, 0.95, 0.95, 0.95, 0.95, 0.95, 0.95, 0.95, 0.95, 0.95, 0.95, 0.95, 0.95, 0.95, 0.95, 0.95, 0.95, 0.95, 0.95, 0.95, 0.95, 0.95, 0.95, 0.95, 0.95, 0.95, 0.95, 0.95, 0.95, 0.95, 0.95, 0.95, 0.95, 0.95, 0.95, 0.95, 0.95, 0.95, 0.95, 0.95, 0.95, 0.95, 0.95, 0.95, 0.95, 0.95, 0.95, 0.95, 0.95, 0.95, 0.95, 0.95, 0.95]\n"
     ]
    }
   ],
   "source": [
    "tx = x_train_std[:1000, [10, 42, 69]] # change input data here\n",
    "y = y_train[:1000] # change target value here\n",
    "y = y.reshape(-1, 1)\n",
    "\n",
    "\n",
    "\n",
    "w_s=[]\n",
    "losses=[]\n",
    "w = np.full((tx.shape[1],1), 1e-16) \n",
    "\n",
    "max_iters=100\n",
    "accs=[]\n",
    "precs=[]\n",
    "recs=[]\n",
    "F1s=[]\n",
    "batch_size = 1 \n",
    "lambda_ = 1e-3\n",
    "gamma = 0.1\n",
    "#1) mean_squared_error_gd \n",
    "for i in range(max_iters):\n",
    "\n",
    "    \"\"\" #1) mean_squared_error_gd\n",
    "    w, loss = mean_squared_error_gd(y, tx, w, max_iters, gamma)\n",
    "\n",
    "    #2) mean_squared_error_sgd\n",
    "    w, loss = mean_squared_error_sgd(y, tx, w, max_iters, gamma) \"\"\"\n",
    "\n",
    "    #3) least_squares\n",
    "    w, loss = least_squares(y, tx)  # change input data here, matrix is not invertible[10, 12, 14/15/20/69]\n",
    "\n",
    "    \"\"\" #4) ridge_regression\n",
    "    w, loss = ridge_regression(y, tx, lambda_)\n",
    "\n",
    "    #5) logistic_regression\n",
    "    w, loss = logistic_regression(y, tx, w, max_iters, gamma)\n",
    "\n",
    "    #6) reg_logistic_regression\n",
    "    w, loss = reg_logistic_regression(y, tx, w, max_iters, gamma, lambda_) \"\"\"\n",
    " \n",
    "    losses.append(loss)\n",
    "\n",
    " \n",
    "    y_pred=tx.dot(w)\n",
    "    y_pred = compute_sigmoid(y_pred)\n",
    "    y_pred[y_pred>0.5] = 1\n",
    "    y_pred[y_pred<=0.5] = 0\n",
    "    \n",
    "    TP = 0\n",
    "    FP = 0\n",
    "    TN = 0\n",
    "    FN = 0\n",
    "    for pred in range(len(y_pred)):\n",
    "        if (y_pred[pred] == 1 and y[pred] == 1):\n",
    "            TP+=1\n",
    "        elif (y_pred[pred] == 1 and y[pred] == 0):\n",
    "            FP+=1\n",
    "        elif (y_pred[pred] == 0 and y[pred] == 1):\n",
    "            FN+=1\n",
    "        else :\n",
    "            TN+=1\n",
    "    acc = (TP+TN)/len(y_pred)\n",
    "    if TP + FP == 0:\n",
    "        prec = 0  # Avoid division by zero\n",
    "    else:\n",
    "        prec = TP / (TP + FP)\n",
    "\n",
    "\n",
    "    if TP + FN == 0:\n",
    "        rec = 0  # Avoid division by zero\n",
    "    else:\n",
    "        rec = TP / (TP + FN)\n",
    "\n",
    "\n",
    "    if prec + rec == 0:\n",
    "        F1score = 0  # Avoid division by zero\n",
    "    else:\n",
    "        F1score = 2 * prec * rec / (prec + rec)\n",
    "\n",
    "\n",
    "    if acc > 0.75 :\n",
    "        w_s.append(w)\n",
    "\n",
    "    accs.append(acc)\n",
    "    precs.append(prec)\n",
    "    recs.append(recs)\n",
    "    F1s.append(F1score)\n",
    "    conf_matrix = np.array([[TP, FP], [FN, TN]])\n",
    "        \n",
    "w_s = np.asarray(w_s)\n",
    "print(\"lambda = \",lambda_,\"| Accuracy moyenne :\",np.mean(accs),\"| Acc>0.75 :\",w_s.shape[0])\n",
    "print(accs)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Local test accuracy of mean_squared_error_gd is 0.359325\n",
      "lambda =  0.001 | Accuracy moyenne : 0.97471 | Acc>0.75 : 1\n",
      "[0.97471]\n"
     ]
    }
   ],
   "source": [
    "changed_data = False # used to make least_squares work\n",
    "\n",
    "if changed_data:\n",
    "    tx = x_train_std[:1000, [10, 42, 69]] # change input data here\n",
    "    y = y_train[:1000] # change target value here\n",
    "    y = y.reshape(-1, 1)\n",
    "else:\n",
    "    # divide dataset into train and test data in order to test prediction on other data than was used for testing\n",
    "    train_data_size = 200000\n",
    "    local_test_data_size = y_train.shape[0] - train_data_size\n",
    "    total_data_size = y.shape[0]\n",
    "\n",
    "    tx = x_train_std[:train_data_size, :]\n",
    "    y = y_train[:train_data_size]\n",
    "    x_local_test = x_train_std[train_data_size:, :]\n",
    "    y_local_test = y_train[train_data_size:]\n",
    "\n",
    "    y = y.reshape(-1, 1)\n",
    "    y_local_test = y_local_test.reshape(-1, 1)\n",
    "\n",
    "w_s=[]\n",
    "losses=[]\n",
    "w = np.full((tx.shape[1],1), 1e-16) \n",
    "\n",
    "max_iters=100\n",
    "accs=[]\n",
    "precs=[]\n",
    "recs=[]\n",
    "F1s=[]\n",
    "batch_size = 1 \n",
    "lambda_ = 1e-3\n",
    "gamma = 0.1\n",
    "\n",
    "gammas = np.arange(0.005, 0.3, 0.05)\n",
    "lambdas = np.arange(0.00005, 0.003, 0.0005)\n",
    "\n",
    "# Test different gammas and lambdas\n",
    "#for gamma in gammas:\n",
    "#    for lambda_ in lambdas:\n",
    "\n",
    "\n",
    "#1) mean_squared_error_gd\n",
    "w, loss = mean_squared_error_gd(y, tx, w, max_iters, gamma)\n",
    "losses.append(loss)\n",
    "y_local_pred = predict_y(w, x_local_test)\n",
    "local_test_accuracy = ( total_data_size - np.sum(y_local_test != y_local_pred) ) / total_data_size\n",
    "print(\"Local test accuracy of mean_squared_error_gd is\", local_test_accuracy)\n",
    "\n",
    "#2) mean_squared_error_sgd\n",
    "w, loss = mean_squared_error_sgd(y, tx, w, max_iters, gamma)\n",
    "losses.append(loss)\n",
    "\n",
    "#3) least_squares\n",
    "if changed_data:\n",
    "    w, loss = least_squares(y, tx)  # change input data here, matrix is not invertible[10, 12, 14/15/20/69]\n",
    "\n",
    "#4) ridge_regression\n",
    "w, loss = ridge_regression(y, tx, lambda_)\n",
    "losses.append(loss)\n",
    "\n",
    "#5) logistic_regression\n",
    "w, loss = logistic_regression(y, tx, w, max_iters, gamma)\n",
    "losses.append(loss)\n",
    "\n",
    "#6) reg_logistic_regression\n",
    "w, loss = reg_logistic_regression(y, tx, w, max_iters, gamma, lambda_)\n",
    "losses.append(loss)\n",
    "\n",
    "\n",
    "y_pred=tx.dot(w)\n",
    "y_pred = compute_sigmoid(y_pred)\n",
    "y_pred[y_pred>0.5] = 1\n",
    "y_pred[y_pred<=0.5] = 0\n",
    "\n",
    "TP = 0\n",
    "FP = 0\n",
    "TN = 0\n",
    "FN = 0\n",
    "for pred in range(len(y_pred)):\n",
    "    if (y_pred[pred] == 1 and y[pred] == 1):\n",
    "        TP+=1\n",
    "    elif (y_pred[pred] == 1 and y[pred] == 0):\n",
    "        FP+=1\n",
    "    elif (y_pred[pred] == 0 and y[pred] == 1):\n",
    "        FN+=1\n",
    "    else :\n",
    "        TN+=1\n",
    "acc = (TP+TN)/len(y_pred)\n",
    "if TP + FP == 0:\n",
    "    prec = 0  # Avoid division by zero\n",
    "else:\n",
    "    prec = TP / (TP + FP)\n",
    "\n",
    "\n",
    "if TP + FN == 0:\n",
    "    rec = 0  # Avoid division by zero\n",
    "else:\n",
    "    rec = TP / (TP + FN)\n",
    "\n",
    "\n",
    "if prec + rec == 0:\n",
    "    F1score = 0  # Avoid division by zero\n",
    "else:\n",
    "    F1score = 2 * prec * rec / (prec + rec)\n",
    "\n",
    "\n",
    "if acc > 0.75 :\n",
    "    w_s.append(w)\n",
    "\n",
    "accs.append(acc)\n",
    "precs.append(prec)\n",
    "recs.append(recs)\n",
    "F1s.append(F1score)\n",
    "conf_matrix = np.array([[TP, FP], [FN, TN]])\n",
    "        \n",
    "w_s = np.asarray(w_s)\n",
    "print(\"lambda = \",lambda_,\"| Accuracy moyenne :\",np.mean(accs),\"| Acc>0.75 :\",w_s.shape[0])\n",
    "print(accs)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.plot(np.linspace(0, max_iters, max_iters), accs)\n",
    "plt.xlabel(\"Iterations\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "CIVIL-459",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
